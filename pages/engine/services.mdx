---
title: 'OPOL Services'
description: 'Detailed overview of the service components in the OPOL stack'
---

The OPOL stack consists of various microservices, databases, and engines that work together to process political information. This page provides detailed information about each component, its purpose, and configuration options.

## Service Categories

<Tabs>
  <Tab title="Overview">
    The OPOL stack is organized into several categories:
    
    <CardGroup cols={2}>
      <Card title="Apps" icon="window-maximize">
        Front-end and dashboard applications
      </Card>
      
      <Card title="Services" icon="microchip">
        Core processing microservices that handle specific tasks
      </Card>
      
      <Card title="Engines" icon="cogs">
        Supporting infrastructure components like databases and third-party tools
      </Card>
      
      <Card title="Databases" icon="database">
        Data storage systems for persistent information
      </Card>
      
      <Card title="Workers" icon="tasks">
        Components that execute processing tasks
      </Card>
    </CardGroup>
  </Tab>
  
  <Tab title="Apps">
    <CardGroup cols={1}>
      <Card title="app-opol-core" icon="tachometer-alt">
        Core dashboard application providing user interface and API coordination.
        
        <Accordion title="Details">
          **Purpose:**
          - Web interface for system monitoring
          - API endpoints for client interactions
          - System health and status reporting
          - Configuration management
          
          **Port:** ${CORE_APP_PORT} (default: 8089)
          
          **Dependencies:**
          - service-scraper
          - service-postgres
          - service-geo
          
          **Configuration Options:**
          ```
          CORE_APP_PORT=8089
          ```
        </Accordion>
      </Card>
    </CardGroup>
  </Tab>
  
  <Tab title="Services">
    <CardGroup cols={2}>
      <Card title="service-scraper" icon="spider-web">
        Content collection service
        
        <Accordion title="Details">
          **Purpose:**
          - Content extraction from websites
          - RSS feed processing
          - API integration for data sources
          - Document normalization
          
          **Port:** ${SCRAPER_SERVICE_PORT} (default: 8081)
          
          **Configuration Options:**
          ```
          SCRAPER_SERVICE_PORT=8081
          ```
        </Accordion>
      </Card>
      
      <Card title="service-embeddings" icon="vector-square">
        Vector processing service
        
        <Accordion title="Details">
          **Purpose:**
          - Text vectorization
          - Embedding generation
          - Semantic similarity computation
          - Vector storage management
          
          **Port:** ${EMBEDDING_SERVICE_PORT} (default: 0420)
          
          **Configuration Options:**
          ```
          EMBEDDING_SERVICE_PORT=0420
          EMBEDDING_MODEL=all-MiniLM-L6-v2  # Default
          ```
        </Accordion>
      </Card>
      
      <Card title="service-entities" icon="tag">
        Entity extraction service
        
        <Accordion title="Details">
          **Purpose:**
          - Named entity recognition
          - Entity classification
          - Entity linking
          - Relationship extraction
          
          **Port:** ${ENTITY_SERVICE_PORT} (default: 1290)
          
          **Configuration Options:**
          ```
          ENTITY_SERVICE_PORT=1290
          ENTITY_MODEL=default  # Options: default, large
          ```
        </Accordion>
      </Card>
      
      <Card title="service-geo" icon="map-marker">
        Geocoding service
        
        <Accordion title="Details">
          **Purpose:**
          - Location name resolution
          - Coordinate assignment
          - Spatial relationship computation
          - GeoJSON generation
          
          **Port:** ${GEO_SERVICE_PORT} (default: 3690)
          
          **Configuration Options:**
          ```
          GEO_SERVICE_PORT=3690
          GEO_PROVIDER=pelias  # Default
          ```
        </Accordion>
      </Card>
      
      <Card title="service-postgres" icon="database">
        Database interface service
        
        <Accordion title="Details">
          **Purpose:**
          - Database migrations
          - Schema management
          - Backup operations
          - Query optimization
          
          **Port:** ${POSTGRES_SERVICE_PORT} (default: 5434)
          
          **Configuration Options:**
          ```
          POSTGRES_SERVICE_PORT=5434
          ```
        </Accordion>
      </Card>
    </CardGroup>
  </Tab>
  
  <Tab title="Engines">
    <CardGroup cols={2}>
      <Card title="engine-ollama" icon="robot">
        Local LLM server
        
        <Accordion title="Details">
          **Purpose:**
          - Host language models locally
          - Process text without external APIs
          - Provide classification capabilities
          - Generate embeddings
          
          **Port:** ${OLLAMA_PORT} (default: 11434)
          
          **Configuration Options:**
          ```
          OLLAMA_PORT=11434
          OLLAMA_MODEL=llama3  # Default model
          ```
          
          **Models:**
          - llama3 (default)
          - mixtral
          - phi3
          - nomic-embed-text (for embeddings)
        </Accordion>
      </Card>
      
      <Card title="engine-pelias-placeholder" icon="map-pin">
        Local geocoding service
        
        <Accordion title="Details">
          **Purpose:**
          - Resolve location names to standard forms
          - Provide offline geocoding capabilities
          - Handle ambiguous place names
          - Support multi-language location references
          
          **Port:** ${PELIAS_PLACEHOLDER_PORT} (default: 4100)
          
          **Configuration Options:**
          ```
          PELIAS_PLACEHOLDER_PORT=4100
          ```
        </Accordion>
      </Card>
      
      <Card title="engine-prefect-server" icon="server">
        Workflow orchestration system
        
        <Accordion title="Details">
          **Purpose:**
          - Schedule and monitor data processing flows
          - Manage task dependencies
          - Handle retries and error recovery
          - Provide execution logs and metrics
          
          **Port:** ${PREFECT_SERVER_PORT} (default: 4200)
          
          **Configuration Options:**
          ```
          PREFECT_SERVER_PORT=4200
          PREFECT_API_URL=http://0.0.0.0:${PREFECT_SERVER_PORT}/api
          ```
        </Accordion>
      </Card>
      
      <Card title="engine-redis" icon="database">
        Queue and cache management
        
        <Accordion title="Details">
          **Purpose:**
          - Job queue management
          - Temporary data caching
          - Inter-service communication
          - Publish/subscribe messaging
          
          **Port:** ${REDIS_PORT} (default: 6379)
          
          **Configuration Options:**
          ```
          REDIS_PORT=6379
          ```
        </Accordion>
      </Card>
      
      <Card title="engine-searxng" icon="search">
        Self-hosted meta-search engine
        
        <Accordion title="Details">
          **Purpose:**
          - Private web search capabilities
          - Integration of multiple search engines
          - Customizable search parameters
          - Privacy-preserving search
          
          **Port:** ${SEARXNG_PORT} (default: 8021)
          
          **Configuration Options:**
          ```
          SEARXNG_PORT=8021
          ```
        </Accordion>
      </Card>
    </CardGroup>
  </Tab>
  
  <Tab title="Databases">
    <CardGroup cols={2}>
      <Card title="database-articles" icon="database">
        Primary PostgreSQL database
        
        <Accordion title="Details">
          **Purpose:**
          - Store article content and metadata
          - Manage entity relationships
          - Host vector embeddings
          - Provide full-text search
          
          **Port:** ${ARTICLES_DB_PORT} (default: 5432)
          
          **Configuration Options:**
          ```
          ARTICLES_DB_USER=postgres
          ARTICLES_DB_PASSWORD=postgres
          ARTICLES_DB_NAME=articles
          ARTICLES_DB_PORT=5432
          ```
        </Accordion>
      </Card>
      
      <Card title="database-prefect" icon="database">
        Workflow orchestration database
        
        <Accordion title="Details">
          **Purpose:**
          - Store workflow execution history
          - Track task states and results
          - Manage scheduled executions
          - Provide execution logs
          
          **Port:** ${PREFECT_DB_PORT} (default: 5433)
          
          **Configuration Options:**
          ```
          PREFECT_DB_USER=postgres
          PREFECT_DB_PASSWORD=postgres
          PREFECT_DB_NAME=prefect
          PREFECT_DB_PORT=5433
          ```
        </Accordion>
      </Card>
    </CardGroup>
  </Tab>
  
  <Tab title="Workers">
    <CardGroup cols={1}>
      <Card title="worker-prefect" icon="cogs">
        Task execution worker
        
        <Accordion title="Details">
          **Purpose:**
          - Execute scheduled and on-demand workflows
          - Process data pipeline tasks
          - Manage Docker-based task execution
          - Report task status and results
          
          **Dependencies:**
          - engine-prefect-server
          - service-postgres
          
          **Configuration Options:**
          ```
          PREFECT_API_URL=http://engine-prefect-server:${PREFECT_SERVER_PORT}/api
          PREFECT_API_KEY=${PREFECT_API_KEY}
          ```
        </Accordion>
      </Card>
    </CardGroup>
    
    <Accordion title="Flow Runners">
      These components are built as Docker images but aren't meant to run continuously. They're used by the Prefect worker to execute specific workflow tasks.
      
      <CardGroup cols={2}>
        <Card title="flowrunner-all" icon="sitemap">
          Complete pipeline runner
          
          **Purpose:**
          - Execute the full data processing pipeline
          - Coordinate all processing stages
          - Provide comprehensive logging
          - Handle dependencies between stages
        </Card>
        
        <Card title="flowrunner-scraping" icon="spider-web">
          Content collection runner
          
          **Purpose:**
          - Execute scraping jobs
          - Process RSS feeds
          - Extract content from websites
          - Format and normalize documents
        </Card>
        
        <Card title="flowrunner-embeddings" icon="vector-square">
          Embedding generation runner
          
          **Purpose:**
          - Generate vector representations of text
          - Compute similarity metrics
          - Index vectors for search
          - Optimize embedding storage
        </Card>
        
        <Card title="flowrunner-entities" icon="tag">
          Entity extraction runner
          
          **Purpose:**
          - Identify named entities in text
          - Classify entity types
          - Extract relationships
          - Link entities across documents
        </Card>
      </CardGroup>
    </Accordion>
    
    <Accordion title="Optional Components">
      These components are included in the configuration but commented out by default. You can enable them for specific use cases.
      
      <CardGroup cols={1}>
        <Card title="Ray Cluster" icon="network-wired">
          Distributed computing framework
          
          **Purpose:**
          - Parallel processing of large datasets
          - Distributed ML model training
          - Horizontal scaling of computations
          - Resource management
          
          **Components:**
          - worker-ray-head
          - worker-ray-node (multiple instances)
          
          **Configuration:**
          ```
          # Uncomment in docker-compose.yml to enable
          ```
        </Card>
      </CardGroup>
    </Accordion>
  </Tab>
</Tabs>

## Infrastructure

<Tabs>
  <Tab title="Networking">
    The OPOL stack uses two Docker networks:
    
    <CardGroup cols={2}>
      <Card title="default" icon="network-wired">
        Internal network for service communication.
        
        **Purpose:**
        - Secure container-to-container communication
        - Service discovery
        - Isolation from host network
      </Card>
      
      <Card title="opol-app-stack" icon="network-wired">
        External network for client access.
        
        **Purpose:**
        - Provide external access to services
        - Enable cross-stack communication
        - Support client-server interactions
        
        **Creation:**
        ```bash
        docker network create --driver bridge opol-app-stack
        ```
      </Card>
    </CardGroup>
  </Tab>
  
  <Tab title="Volumes">
    The stack uses several persistent volumes:
    
    <CardGroup cols={3}>
      <Card title="articles_db_data" icon="hdd">
        Persistent storage for the main database
      </Card>
      
      <Card title="prefect_data" icon="hdd">
        Storage for workflow state
      </Card>
      
      <Card title="r2r_db_data" icon="hdd">
        Storage for additional databases
      </Card>
    </CardGroup>
  </Tab>
  
  <Tab title="Configuration">
    All services are configured through environment variables defined in `.env.local`. The key variables are:
    
    <AccordionGroup>
      <Accordion title="Core Settings">
        ```
        # Core application settings
        CORE_APP_PORT=8089
        
        # Local LLM settings
        LOCAL_LLM=TRUE
        OLLAMA_MODEL=llama3
        OLLAMA_PORT=11434
        
        # OpenAI (alternative to local LLM)
        # LOCAL_LLM=FALSE
        # OPENAI_API_KEY=your-key-here
        ```
      </Accordion>
      
      <Accordion title="Database Settings">
        ```
        # Articles database
        ARTICLES_DB_USER=postgres
        ARTICLES_DB_PASSWORD=postgres
        ARTICLES_DB_NAME=articles
        ARTICLES_DB_PORT=5432
        
        # Prefect database
        PREFECT_DB_USER=postgres
        PREFECT_DB_PASSWORD=postgres
        PREFECT_DB_NAME=prefect
        PREFECT_DB_PORT=5433
        ```
      </Accordion>
      
      <Accordion title="Service Ports">
        ```
        # Service ports
        SCRAPER_SERVICE_PORT=8081
        EMBEDDING_SERVICE_PORT=0420
        ENTITY_SERVICE_PORT=1290
        GEO_SERVICE_PORT=3690
        POSTGRES_SERVICE_PORT=5434
        PELIAS_PLACEHOLDER_PORT=4100
        PREFECT_SERVER_PORT=4200
        REDIS_PORT=6379
        SEARXNG_PORT=8021
        ```
      </Accordion>
    </AccordionGroup>
  </Tab>
</Tabs>

## Management

<Tabs>
  <Tab title="Service Control">
    <Steps>
      <Step title="Starting and Stopping">
        You can manage individual services with Docker Compose:
        
        ```bash
        # Start a specific service
        docker compose up -d service-name
        
        # Stop a specific service
        docker compose stop service-name
        
        # Restart a service
        docker compose restart service-name
        
        # View service logs
        docker compose logs -f service-name
        ```
      </Step>
      
      <Step title="Scaling Services">
        Some services can be scaled horizontally:
        
        ```bash
        # Scale a service to multiple instances
        docker compose up -d --scale service-name=3
        ```
        
        <Info>
          Not all services support scaling. Those that maintain state (like databases) typically don't.
        </Info>
      </Step>
      
      <Step title="Monitoring Health">
        You can check service health through:
        
        1. OPOL Dashboard (http://localhost:8089/dashboard)
        2. Prefect UI (http://localhost:4200)
        3. Docker Compose status:
           ```bash
           docker compose ps
           ```
      </Step>
    </Steps>
  </Tab>
  
  <Tab title="Common Configurations">
    <AccordionGroup>
      <Accordion title="Using External LLM APIs">
        To use OpenAI instead of local models:
        
        ```
        # In .env.local
        LOCAL_LLM=FALSE
        OPENAI_API_KEY=your-key-here
        OPENAI_MODEL=gpt-4-turbo
        ```
      </Accordion>
      
      <Accordion title="Configuring Database Connections">
        To use a managed database:
        
        ```
        # In .env.local
        ARTICLES_DB_HOST=your-managed-db-host
        ARTICLES_DB_PORT=5432
        ARTICLES_DB_USER=your-username
        ARTICLES_DB_PASSWORD=your-password
        ARTICLES_DB_NAME=your-db-name
        ```
      </Accordion>
      
      <Accordion title="Adding Custom Search Sources">
        To add sources to SearXNG:
        
        1. Edit `core/configs/searxng/searxng-settings.yml`
        2. Add your custom search engines
        3. Restart the SearXNG service:
           ```bash
           docker compose restart engine-searxng
           ```
      </Accordion>
    </AccordionGroup>
  </Tab>
</Tabs>

## Next Steps

<CardGroup cols={2}>
  <Card title="Data Pipeline" icon="diagram-project" href="/engine/data-pipeline">
    Learn how data flows through the services
  </Card>
  
  <Card title="Classification Framework" icon="tags" href="/engine/classification-framework">
    Understand the LLM classification system
  </Card>
  
  <Card title="Installation" icon="download" href="/development/installation">
    Set up the complete stack
  </Card>
  
  <Card title="Configuration" icon="sliders" href="/development/configuration">
    Advanced configuration options
  </Card>
</CardGroup>