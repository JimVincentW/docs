---
title: 'LLM Classification Framework'
description: 'Define analytical frameworks in natural language and apply them systematically'
---



## Schema Definition

Users can define schemas in two ways:

<Tabs>
  <Tab title="Simple Format">
    For basic classifications, users can define a single field with an instruction:
    
    ```python
    text = "Let's do something very bad, says very untrustworthy president"
    
    instruction = "On a 1-10 scale, how much does this article indicate something bad happening in politics?"
    
    int_value = xclass.classify("int", instruction, text)
    
    # Result: 9
    ```
    
    This approach works well for extracting single values or simple classifications.
  </Tab>
  
  <Tab title="Pydantic Models">
    For more complex analytical frameworks, users can define Pydantic models where each field represents a dimension of analysis:
    
    ```python
    class PoliticalAnalysis(BaseModel):
        """
        We want to analyze political news content across multiple dimensions.
        """
        
        keywords: List[str] = Field(
            description="The keywords most relevant to this text, focusing on political significance"
        )
        
        relevance_level: int = Field(
            description="On a 1-10 scale, how much the content relates to significant political developments. A 1 might be a celebrity's opinion on an issue, and a 10 might be an invasion of one country by another."
        )
        
        diplomatic_framing: float = Field(
            description="From 0.0 to 1.0, the extent to which the content frames issues in terms of diplomatic solutions versus confrontational approaches."
        )
        
        economic_focus: float = Field(
            description="From 0.0 to 1.0, what percentage of the content focuses on economic aspects of the political situation."
        )
    ```
    
    The model documentation and field descriptions serve as instructions to the LLM, guiding how it should extract and structure information.
  </Tab>
</Tabs>

## Technical Implementation

Behind the scenes, the framework uses several components to ensure reliable and consistent results:

<CardGroup cols={2}>
  <Card title="Schema Compilation" icon="code">
    Converts user definitions into structured prompts for LLMs
  </Card>
  
  <Card title="Execution Engine" icon="gears">
    Handles sending prompts to LLMs and processing responses
  </Card>
  
  <Card title="Validation" icon="check">
    Ensures outputs conform to the expected schema
  </Card>
  
  <Card title="Results Storage" icon="database">
    Stores structured outputs with links to source documents
  </Card>
</CardGroup>

The system handles:

- Converting between natural language and structured data types
- Ensuring consistent application of definitions across documents
- Managing LLM context limitations for processing large texts
- Tracking provenance between definitions and results

## Use Cases

The LLM Classification Framework enables numerous analytical approaches previously difficult to implement at scale:

<AccordionGroup>
  <Accordion title="Multi-dimensional Political Positioning">
    Instead of reducing political positions to a single left-right spectrum, analysts can define multiple independent dimensions (economic, social, foreign policy, environmental, etc.) and position texts along all of them simultaneously.
    
    <Frame>
      <img src="/images/multidimensional_analysis.png" alt="Multidimensional Analysis" />
    </Frame>
  </Accordion>
  
  <Accordion title="Issue Framing Analysis">
    Researchers can define different framing approaches for political issues (e.g., "immigration as economic issue" vs. "immigration as security issue") and systematically track how different sources frame topics over time.
  </Accordion>
  
  <Accordion title="Argument Mapping">
    By defining schemas that extract claims, evidence, and reasoning patterns, users can map the structure of political arguments across different sources and identify persuasive strategies.
  </Accordion>
  
  <Accordion title="Comparative Analysis">
    The same analytical framework can be applied across different languages, regions, or time periods, enabling systematic comparative studies that would be impractical with manual methods.
  </Accordion>
  
  <Accordion title="Custom Classification Schemes">
    Rather than using predetermined topic models or classification systems, researchers can define custom categories tailored to their specific research questions.
  </Accordion>
</AccordionGroup>

## Integration with OPOL

The LLM Classification Framework is deeply integrated with the OPOL data engine:

- Classification results are stored in the database alongside source documents
- Results can be queried with structured filters or semantic search
- Geocoded entities can be combined with classifications for spatial analysis
- Temporal data allows tracking classification trends over time

## Usage in HQ

In the HQ interface, users can:

1. Create and edit classification schemas through a visual interface
2. Select documents for analysis based on search results or collections
3. Run classifications on selected documents
4. Visualize results through various interfaces:
   - Charts and graphs
   - Spatial representations on the globe
   - Temporal trend analysis
   - Network visualizations

## Technical Challenges

Implementing this framework presents several significant challenges that we continue to address:

<AccordionGroup>
  <Accordion title="Consistency and Reliability">
    Natural language is inherently ambiguous, and LLMs can be inconsistent. We address this through:
    
    - Careful prompt engineering
    - Multiple validation checks
    - Calibration mechanisms
    - Statistical reliability measures
  </Accordion>
  
  <Accordion title="Transparency and Reproducibility">
    For research integrity, users must understand how results were derived. We provide:
    
    - Explicit linking between definitions and results
    - Full provenance tracking
    - Audit trails for refinement loops
    - Version control for schemas
  </Accordion>
  
  <Accordion title="Handling Edge Cases">
    Political texts often contain ambiguity, metaphor, and implicit information. Our system includes:
    
    - Confidence scoring for extractions
    - Explicit handling of edge cases in schema definitions
    - Flagging of problematic extractions for human review
  </Accordion>
  
  <Accordion title="Scale and Performance">
    Processing large document collections with LLMs is computationally expensive. We optimize through:
    
    - Batched processing
    - Caching of similar queries
    - Progressive refinement approaches
    - Selective application of complex schemas
  </Accordion>
</AccordionGroup>

## Future Development

The LLM Classification Framework is continually evolving along several directions:

<CardGroup cols={2}>
  <Card title="Collaborative Schema Development" icon="users">
    Enabling teams to collaboratively refine analytical frameworks
  </Card>
  
  <Card title="Schema Versioning" icon="code-branch">
    Tracking how analytical frameworks evolve over time
  </Card>
  
  <Card title="Cross-Modal Analysis" icon="photo-film">
    Extending the system to handle multimodal political content
  </Card>
  
  <Card title="Methodological Validation" icon="check-double">
    Developing tools to validate schema reliability
  </Card>
  
  <Card title="Integration with Classical Methods" icon="chart-line">
    Creating bridges between LLM-driven analysis and traditional computational social science
  </Card>
</CardGroup>

## Additional Resources

<CardGroup cols={2}>
  <Card title="User Guide" icon="book" href="/app/classification-system">
    How to use the classification system in HQ
  </Card>
  
  <Card title="API Reference" icon="code" href="/development/api-reference">
    Programmatic access to the classification framework
  </Card>
  
  <Card title="Example Schemas" icon="file-code" href="/examples/schemas">
    Sample classification schemas for different analytical goals
  </Card>
  
  <Card title="Research Background" icon="graduation-cap" href="/research">
    Academic foundations of our approach
  </Card>
</CardGroup>