---
title: "Schemas"
description: "Define analysis tasks in natural language. Apply them at scale."
---

# Schemas

> Define analysis tasks in natural language. Apply them at scale.

## What Are Schemas?

Schemas are reusable analysis templates in plain English. Define what to extract from documents, AI applies it consistently across documents.

**Example:** Media bias analysis schema:

```json
{
  "source_type": {
    "type": "string",
    "description": "Primary source: [government, activist, expert, anonymous]"
  },
  "emotional_intensity": {
    "type": "number",
    "description": "Emotional intensity: 1-10 scale"
  },
  "framing": {
    "type": "string",
    "description": "Issue framing: [economic, security, moral, procedural]"
  },
  "geographic_scope": {
    "type": "string",
    "description": "Geographic scope: [local, national, international]"
  }
}
```

Result: Comparison of how different outlets frame the same stories.

## Creating Your First Schema

### Step 1: Define Your Questions

Start with the analytical questions you want to answer:

- What policy positions are mentioned?
- How do different sources frame the same issue?
- What stakeholders are involved?
- What's the timeline for implementation?

### Step 2: Write Clear Instructions

**Good instructions:**
```json
{
  "department": {
    "type": "string",
    "description": "Department or agency name"
  },
  "amount_millions": {
    "type": "number",
    "description": "Amount in millions of dollars"
  },
  "change_type": {
    "type": "string",
    "description": "Change from previous year: [increase, decrease, same]"
  }
}
```

**Avoid vague instructions:**
```json
{
  "financial_info": {
    "type": "string",
    "description": "Extract important financial information"
  }
}
```

### Step 3: Choose Data Types

**Text (string):** Categories, descriptions, names, locations  
**Numbers:** Ratings, amounts, counts, scales  
**Lists (array):** Multiple items, themes, categories  
**Dates:** Timestamps, deadlines, events

## Data Type Examples

**String (Text):**
```json
"source_type": {
  "type": "string",
  "description": "News source: [mainstream, alternative, government, independent]"
}
```

**Array (List):**
```json
"framing_categories": {
  "type": "array",
  "description": "Issue framing: [economic, security, moral, procedural]"
}
```

**Number:**
```json
"security_stance": {
  "type": "number",
  "description": "Immigration position: 1-10 scale (1=pro-immigration, 10=security-focused)"
}
```

### Step 4: Test and Refine

Always test on 2-3 sample documents first:
1. Check output quality matches expectations
2. Identify gaps in extracted data
3. Refine instructions based on results

## How It Works

<video controls width="100%">
  <source src="/images/schema-view-5.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

**Pattern:** Domain expertise → Natural language instructions → Structured JSON output

**Benefits:**
- No coding required
- Reproducible results
- Transparent methodology
- Continuously improvable

## Running Analysis

<Steps>
<Step title="Select Content">
Choose individual assets or entire bundles to analyze
</Step>
<Step title="Pick Schema">
Select your analysis template from available schemas
</Step>
<Step title="Configure Settings">
Choose AI model and processing options
</Step>
<Step title="Run Analysis">
Process all selected content with your schema
</Step>
</Steps>

### AI Models

**Cloud Models:** OpenAI GPT-4/3.5, Google Gemini, Anthropic Claude  
**Local Models:** Ollama (Llama, Mistral, Code Llama)

## Best Practices

### Write Specific Instructions

**Good:**
```json
{
  "department": {
    "type": "string",
    "description": "Department name (e.g., Education, Defense, Health)"
  },
  "amount_millions": {
    "type": "number",
    "description": "Budget amount in millions of dollars"
  }
}
```

**Avoid:**
```json
{
  "financial_info": {
    "type": "string",
    "description": "Extract important financial information"
  }
}
```

### Start Simple, Then Expand

1. Extract basic entities (people, organizations, locations)
2. Add analysis layers (sentiment, categorization)
3. Include complex reasoning (relationships, advanced analysis)

### Test Before Scaling

<Warning>
Always test on 2-3 sample documents before processing large batches.
</Warning>

## Sharing Schemas

**Schema Library:** Upload successful schemas and browse others' work  
**Transparency:** Others can see, critique, and replicate your methodology  
**Community:** Builds cumulative knowledge in the field

## Next Steps

<Steps>
<Step title="Create Schema">
Start with simple entity extraction and test on sample documents
</Step>
<Step title="Upload Content">
Use [Assets & Bundles](/docs/assets) to organize your documents
</Step>
<Step title="Run Analysis">
Apply your schema and choose appropriate AI models
</Step>
<Step title="Explore Results">
Visualize findings with [Analysis Dashboards](/docs/dashboards)
</Step>
<Step title="Scale Up">
Create complex schemas and explore [Chat & MCP](/docs/chat)
</Step>
</Steps>

## Related Topics

<CardGroup cols={2}>
<Card title="Assets & Bundles" icon="folder" href="/docs/assets">
Learn how to upload and organize your content for analysis
</Card>
<Card title="Classification System" icon="cog" href="/docs/classification-system">
Understand how schemas power systematic content analysis
</Card>
<Card title="Analysis Dashboards" icon="chart-line" href="/docs/dashboards">
Visualize your schema results with interactive dashboards
</Card>
<Card title="Chat & MCP" icon="comments" href="/docs/chat">
Use conversational AI to work with your schemas and data
</Card>
</CardGroup>