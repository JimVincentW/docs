---
title: "Schemas"
description: "Tell the AI what to extract from your documents"
---

# Schemas

A schema is a set of instructions for extracting structured data from documents. You describe what you want in plain English, the AI applies it consistently across hundreds or thousands of items.

## What You Get

Here's output from a schema analyzing EU Parliament speeches on migration:

<Frame>
  <img src="/images/result-speeches-light.png" alt="Schema results showing extracted fields from parliamentary speeches" className="block dark:hidden" />
  <img src="/images/result-speeches-dark.png" alt="Schema results showing extracted fields from parliamentary speeches" className="hidden dark:block" />
</Frame>

Each speech gets analysed for the same fields: position summary, security stance (1-10), location mentions, talking point topics, migration attitude, governance focus, rhetoric style. The schema defines what to extract - the AI does the extraction.

With structured output, you can filter, compare, and visualise. Which speakers emphasise humanitarian concerns vs. security? How does rhetoric differ by country? That's the point.

---

## Building a Schema

Start with your actual questions. What do you want to know about your documents?

- What positions are being taken?
- How is the issue framed?
- Who's mentioned, and in what context?
- What's the emotional temperature?

Then turn each question into an extraction field.

### Good Instructions vs. Vague Instructions

The difference between useful output and noise is specificity.

<Tabs>
  <Tab title="✓ This works">
    <CardGroup cols={2}>
      <Card title="security_stance" icon="shield">
        **Type:** Number (1-10)  
        **Extract:** Position on border security. 1 = open borders, 10 = strict enforcement
      </Card>
      <Card title="talking_point_topics" icon="list">
        **Type:** List  
        **Extract:** Main topics discussed - migration policy, demographic change, EU solidarity, public services, etc.
      </Card>
    </CardGroup>
    
    *Clear scales, concrete categories, examples of valid values.*
  </Tab>
  <Tab title="✗ This doesn't">
    <Card title="position" icon="question">
      **Type:** Text  
      **Extract:** What is their position on the issue?
    </Card>
    
    *Too vague. Which issue? What aspects of their position? The AI will guess, and guesses vary.*
  </Tab>
</Tabs>

### Field Types

| Type | Use for | Example |
|------|---------|---------|
| **String** | Freeform text, summaries, answers, categories | `summary: "Speaker argues for..."` |
| **Number** | Ratings, scales, counts, amounts | `security_stance: 7` |
| **List** | Multiple values, tags, topics | `topics: ["migration", "EU solidarity"]` |

Everything is stored as strings or numbers - there's no special date type. Timestamps are strings in a parseable format (`"2024-03-15"`).

**Binary fields for filtering:** It's often useful to include 0/1 or yes/no fields for filtering results. Something like `is_spam: 0` or `is_relevant: 1` lets you quickly filter out noise in dashboards.

### Special Field Names

Certain field names unlock specific features when you view results:

| Field name | What it enables |
|------------|-----------------|
| `location` | Geographic maps - locations get geocoded and plotted |
| `timestamp` | Time series charts - combine with number fields to track changes over time |
| `summary` | Highlighted in result views as the main description |
| `tags` | Counted and aggregated across results |

Other list fields also get counted automatically. If you extract `talking_point_topics` as a list, you'll see frequency distributions in dashboards.

Numbers with defined scales (1-10, 1-5) work well for comparative analysis - they enable meaningful aggregation and time series when combined with timestamps.

---

## Tips

**Include examples in your instructions.** "Source type: government, activist, expert, journalist, or anonymous" gives the AI a bounded set to work with.

**Use scales for subjective measures.** "Emotional intensity (1-10)" is more useful than "how emotional is it?" because you can aggregate and compare.

**Start simple, then add.** Begin with basic extraction (who, what, where), confirm it works, then layer in analysis fields (sentiment, framing, stance).

**Look at failures.** When extraction is wrong or inconsistent, the instructions usually need tightening. What did the AI misunderstand?

---

## Sharing Schemas

Schemas can be uploaded to the library for others to use. They can see your methodology, critique it, replicate it, build on it. Transparency about how analysis is done matters - it's what separates systematic research from vibes.

---

## Related pages

<CardGroup cols={2}>
<Card title="Running Analysis" icon="play" href="/pages/concepts/running-analysis">
Apply schemas to your documents
</Card>
<Card title="Curating Fragments" icon="star" href="/pages/concepts/curating-fragments">
Promote extractions to persistent metadata
</Card>
<Card title="Assets & Bundles" icon="folder" href="/pages/app/assets">
Upload and organise documents for analysis
</Card>
<Card title="Dashboards" icon="chart-line" href="/pages/app/dashboards">
Visualise results with charts and tables
</Card>
</CardGroup>
