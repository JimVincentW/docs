---
title: 'App Setup'
description: 'Configure providers and foundation services'
---
HQ uses foundation services to power different capabilities. Configure them in the **Provider Configuration** panel on the home screen.

## Foundation Services

<CardGroup cols={2}>
  <Card title="Language Models" icon="brain">
    Chat, classification, structured extraction. The core AI capability.
  </Card>
  <Card title="Embeddings" icon="vector-square">
    Vector search, similarity matching, semantic discovery within infospaces.
  </Card>
  <Card title="Web Search" icon="globe">
    Live web results for chat - ground responses in current information.
  </Card>
  <Card title="Geocoding" icon="location-dot">
    Extract and map locations from your documents. Powers geographic visualizations.
  </Card>
</CardGroup>

<img className="hidden dark:block" src="/images/home-config-dark.png" alt="App Setup" width="100%" />
<img className="block dark:hidden" src="/images/home-config-light.png" alt="App Setup" width="100%" />

Each service type supports multiple providers. Pick what fits your needs — cloud APIs, local inference, or a mix.

---

## API Key Storage

Two storage modes for each provider:

| Mode | What it does | Use when |
|------|--------------|----------|
| **Runtime Only** | Keys stay in your browser | Quick testing, interactive use |
| **Save for Tasks** | Keys encrypted in database | Background jobs, large analysis runs, automation |

<Warning>
**Background tasks require saved keys.** The Celery worker that processes large analysis runs can't access your browser. If jobs hang or fail, check that you've saved keys to the backend.
</Warning>


---

## Providers

### Language Models

| Provider | Get Key |
|----------|---------|
| Anthropic | [console.anthropic.com](https://console.anthropic.com) |
| OpenAI | [platform.openai.com](https://platform.openai.com) |
| Google | [aistudio.google.com](https://aistudio.google.com) |
| Ollama | Local — no key needed |


### Ollama 

Ollama is a local language model server that has many models available and is a great way to get started with local inference.

<Steps>
    <Step title="Select Ollama as LLM and Embedding Provider">
    <img className="hidden dark:block" src="/images/ollama-select-dark.png" alt="Ollama" width="100%" />
    <img className="block dark:hidden" src="/images/ollama-select-light.png" alt="Ollama" width="100%" />
</Step>
<Step title="Select a model">
    <img className="hidden dark:block" src="/images/ollama-model-menu-dark.png" alt="Ollama" width="100%" />
    <img className="block dark:hidden" src="/images/ollama-model-menu-light.png" alt="Ollama" width="100%" />
</Step>
</Steps>

### Embeddings

Used for vectorizing content in your infospaces. Configure separately from language models.

| Provider | Notes |
|----------|-------|
| OpenAI | Reliable, widely used |
| Ollama | Local embeddings, complete privacy |

### Web Search

Enables the chat to pull in live search results.

| Provider | Get Key |
|----------|---------|
| Tavily | [tavily.com](https://tavily.com) |
| SearXNG | (soon back integrated in the stack)

### Geocoding

Location extraction uses Nominatim. Self-hosted deployments include it by default. No API key needed for local Nominatim.

---

## Verifying Setup

1. Open **Chat** and send a message — confirms language model works
2. Upload an asset and check if it appears in vector search — confirms embeddings
3. Ask chat to search the web — confirms web search
4. Run an analysis with location fields — confirms geocoding

---

## Next Steps

<CardGroup cols={2}>
  <Card title="Infospaces" icon="folder" href="/pages/app/infospaces">
    Create workspaces for your projects
  </Card>
  <Card title="Schemas" icon="microscope" href="/pages/app/schemas">
    Define what to extract from documents
  </Card>
</CardGroup>
