
# Why do we use Google's models'
They beat everyone on the market as of today in price, and such a system profits from extensive llm capabilities.

If you have (understandable) concerns about using Google's models, you can choose to run a local model with Ollama.

If you are a developer this is accessible to you via running a docker container.

If you are not a developer: we are working on finding and implementic a secure for private and secure LLM apis.
If you have tips for providers, please let us know at engage@open-politics.org